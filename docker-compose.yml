version: "3"

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    
    # CPU optimizations
    deploy:
      resources:
        limits:
          cpus: '0.8'  # Adjust based on your CPU cores
          memory: 8G   # Increase if you have more RAM
    
    environment:
      # CPU optimization settings
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_FLASH_ATTENTION=false
      - OLLAMA_LLM_LIBRARY=cpu
      - OMP_NUM_THREADS=4  # Adjust to your CPU cores
      
    # Use a smaller, faster model for CPU inference
    entrypoint: >
      sh -c "ollama serve &
             sleep 10 &&
             ollama pull llama3.2:1b &&
             ollama pull phi3:mini &&
             wait"

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
     # - OLLAMA_API_URL=http://ollama:11434/api/generate
      - OLLAMA_MODEL=llama3.2:1b  # Smaller model for faster inference
      - PORT=8000
      # Backend optimizations
      - REQUEST_TIMEOUT=3000  # 5 minutes timeout
      - MAX_TOKENS=512       # Limit response length
    volumes:
      - ./backend:/app
      - ./data:/app/data
    depends_on:
      - ollama
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "80:80"
    depends_on:
      - backend
    restart: unless-stopped

  jenkins:
    image: jenkins/jenkins:lts
    ports:
      - "8080:8080"
      - "50000:50000"
    user: root
    volumes:
      - jenkins_data:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
      - ./jenkins/scripts:/var/jenkins_scripts
      - /usr/bin/docker:/usr/bin/docker:ro
      - /usr/lib/x86_64-linux-gnu/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7:ro
    environment:
      - DOCKER_HOST=unix:///var/run/docker.sock
      - JENKINS_OPTS=--httpPort=8080 --httpListenAddress=0.0.0.0
      - PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
    depends_on:
      - frontend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 2G
    entrypoint: >
      sh -c "
        apt-get update && 
        apt-get install -y curl &&
        curl -fsSL https://get.docker.com -o get-docker.sh &&
        sh get-docker.sh &&
        usermod -aG docker jenkins &&
        /usr/local/bin/jenkins.sh
      "

volumes:
  ollama_data:
  jenkins_data: